# -*- coding: utf-8 -*-
"""Yogyakarta Tourist Destination.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eYD9VzEDJsHyYDReLfP-5z0FdIJULWR
"""

# Commented out IPython magic to ensure Python compatibility.
# Data Processing
import pandas as pd
import numpy as np
from zipfile import ZipFile
from pathlib import Path

# Data Visualization
import seaborn as sns
import matplotlib.pyplot as plt

# %matplotlib inline
sns.set_palette('Set1')
sns.set()

# Data Modelling
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Avoiding warning while plotting on seaborn
import warnings
warnings.filterwarnings('ignore')

# Uploading file
import os

"""**Preparing Dataset**"""

# safe each dataset into variable

rating = pd.read_csv('/content/tourism_rating.csv')
place = pd.read_csv('/content/tourism_with_id.csv')
user = pd.read_csv('/content/user.csv')

"""* Tourism_with_id.csv - berisi informasi 5 kota besar di Indonesia, untuk kasus
ini hanya Yogyakarta yang akan digunakan
* User.csv - berisi informasi pengguna untuk membuat fitur rekomendasi
* Tourism_rating.csv - berisi informasi pengguna, destinasi wisata, dan rating untuk membuat sistem rekomendasi berdasarkan rating

Data Features Exploration, untuk memahami karakteristik dan pola yang terkandung dalam setiap fitur (kolom) dalam dataset
"""

place.head()

"""Hapus kolom Unnamed: 11 dan Unnamed: 12 karena tidak dibutuhkan untuk tahap analisis."""

place = place.drop(['Unnamed: 11', 'Unnamed: 12'], axis=1)
place.head()

"""Menampilkan tempat yang ada di Yogyakarta karena akan melakukan rekomendasi untuk destinasi wisata yang ada di Yogyakarta"""

# Show just Yogyakarta
place = place[place['City'] == 'Yogyakarta']
place.head()

"""Untuk melihat rata-rata dari kolom Time_Minutes"""

place.loc[:, ['Time_Minutes']].mean(axis = 0)

place.info()

"""Disini terlihat bahwa ada missing value di kolo Time_Minutes"""

place.head()

rating.info()

"""Melakukan merge untuk memberikan informasi atau untuk mengetahui hubungan user mana yang memberikan rating tinggi untuk wisata A"""

# change data rating so that it will contain destination rating pada of Yogyakarta

rating = pd.merge(rating, place[['Place_Id']], how='right', on='Place_Id')
rating.head()

rating.shape

"""Sama seperti diatas, dilakukan merge untuk memberikan informasi tambahan"""

user.head()

# change respondents' data into Yogyakarta destination visitors

user = pd.merge(user, rating[['User_Id']], how='right', on='User_Id').drop_duplicates().sort_values('User_Id')
user.head()

user.shape

"""Exploratory Data Analysis"""

# creating datafram that contains locations with most rating
top_10 = rating['Place_Id'].value_counts().reset_index()[0:10]
# Rename the 'index' column to 'Place_Id' for merging
top_10 = top_10.rename(columns={'index': 'Place_Id'})
top_10 = pd.merge(top_10, place[['Place_Id','Place_Name']], how='left', on='Place_Id') # Merge on 'Place_Id'

# creating visualization that contains most visited destinations
plt.figure(figsize=(8,5))
sns.barplot(x='Place_Id', y='Place_Name', data=top_10) # Use 'Place_Id' instead of 'Place_Id_x'
plt.title('Sum of Most Rated Destinations', pad=20)
plt.ylabel('Sum of Rating')
plt.xlabel('Location Name')
plt.show()

"""Destinasi dengan rating tertinggi yang pertama yaitu Taman Sungai Mudal, Pantai Ngandong, Pantai Kesirat, Pantai Parangtritis, dan Pasar Beringharjo."""

# creating visualization of sum category for Yogyakarta destinations

sns.countplot(y='Category', data=place)
plt.title('Comparison of Summary Tourism Category in Yogyakarta', pad=20)
plt.show()

"""Kategori destinasi wisata dengan rating tertinggi yaitu Taman Hiburan, Bahari, dan Budaya. Sedangkan Pusat Perbelanjaan mendapatkan rating terendah."""

# visualizing visitors distribution

plt.figure(figsize=(5,3))
sns.boxplot(user['Age']);
plt.title('Visitor Age Distribution', pad=20)
plt.show()

"""Terlihat distribusi usia pengunjung tidak terdapat outlier"""

# visualizing entrance fee range for destinations

plt.figure(figsize=(12,6))
sns.boxplot(place['Price'])
plt.title('Entrance Free Distribution for Yogyakarta Tourist Destination', pad=20)
plt.show()

"""Disini terlihat bahwa ada outlier dalam konteks harga tiket masuk bisa mengindikasikan adanya kesalahan input data, tarif khusus untuk kelompok tertentu, atau memang destinasi wisata tersebut menawarkan layanan atau fasilitas yang sangat berbeda dibandingkan dengan yang lain.

Data gabungan ini dapat berguna untuk berbagai analisis, seperti mengidentifikasi kategori populer, memahami pola pengeluaran, dan mengambil keputusan berdasarkan data
"""

# aggregating the Price and Time_Minutes for Category destination
place.groupby("Category").agg({"Price":["mean", "sum"],
                       "Time_Minutes":["mean", "sum"]})

# filtering city origin of visitors
askot = user['Location'].apply(lambda x : x.split(',')[0])

# visualizing city origin of visitors
plt.figure(figsize=(8,6))
sns.countplot(y=askot)
plt.title('Sum of Visitors Origin')
plt.show()

"""Jumlah asal pengunjung yang terbanyak berasal dari daerah Bekasi kemudian Semarang. Sedangkan yang paling sedikit berasal dari Nganjuk dan juga Madura.

**Data Preparation**
"""

# reading dataset for encoding

df = rating.copy()
df.head()

"""**Encoding**

Melakukan encoding categorical features dan normalizing numerical features. Hal ini memastikan bahwa data berada dalam format yang sesuai untuk melatih model sistem rekomendasi.
"""

def dict_encoder(col, data=df):

  # changing column of dataframe into list with unique value
  unique_val = data[col].unique().tolist()

  # enumerating column value of dataframe
  val_to_val_encoded = {x: i for i, x in enumerate(unique_val)}

  # encoding process from numbers to column value of dataframe
  val_encoded_to_val = {i: x for i, x in enumerate(unique_val)}
  return val_to_val_encoded, val_encoded_to_val

# Encoding User_Id
user_to_user_encoded, user_encoded_to_user = dict_encoder('User_Id')

# Mapping User_Id into dataframe
df['user'] = df['User_Id'].map(user_to_user_encoded)

# Encoding Place_Id
place_to_place_encoded, place_encoded_to_place = dict_encoder('Place_Id')

# Mapping Place_Id into dataframe place
df['place'] = df['Place_Id'].map(place_to_place_encoded)

# getting length of user & place
num_users, num_place = len(user_to_user_encoded), len(place_to_place_encoded)

# changing rating into float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# getting minimum and maximum rating
min_rating, max_rating = min(df['Place_Ratings']), max(df['Place_Ratings'])

print(f'Number of User: {num_users}, Number of Place: {num_place}, Min Rating: {min_rating}, Max Rating: {max_rating}')

# randomizing dataset
df = df.sample(frac=1, random_state=42)
df.head(2)

"""**Modeling with RecomenderNet**

Dalam analisis ini, digunakan model regresi RecomenderNet.
RecomenderNet adalah model yang kuat dan fleksibel untuk membangun sistem rekomendasi yang efektif. Model ini mampu memberikan rekomendasi yang lebih personal, akurat, dan relevan dibandingkan dengan model tradisional.

Dataset ini dibagi menjadi set training dan testing dengan rasio 80:20
"""

# creating x variable for matching the user into one value
x = df[['user', 'place']].values

# crating y variable for initiatin the rating
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# allocating data training 80% & data validation 20%
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

class RecommenderNet(tf.keras.Model):

  # Function initialization
  def __init__(self, num_users, num_places, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_places = num_places
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.places_embedding = layers.Embedding( # layer embeddings places
        num_places,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.places_bias = layers.Embedding(num_places, 1) # layer embedding places bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # layer embedding 2
    places_vector = self.places_embedding(inputs[:, 1]) # layer embedding 3
    places_bias = self.places_bias(inputs[:, 1]) # layer embedding 4

    dot_user_places = tf.tensordot(user_vector, places_vector, 2)

    x = dot_user_places + user_bias + places_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_place, 50) # model initialization

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.0004),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_root_mean_squared_error')<0.25):
      print('Fulfilled expected validation matrix')
      self.model.stop_training = True

# begin the training

history = model.fit(
    x = x_train,
    y = y_train,
    epochs = 100,
    validation_data = (x_val, y_val),
    callbacks = [myCallback()]
)

"""Evaluasi menggunakan metriks root mean squared error dengan hasil 0.3195 dan val root mean squared error dengan hasil 0.3490"""

# showing the plot loss and validation
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.ylim(ymin=0, ymax=0.4)
plt.legend(['train', 'test'], loc='center left')
plt.show()

"""**Predictions of Recomendation Destination**"""

# dataframe preparation
place_df = place[['Place_Id','Place_Name','Category','Rating','Price']]
place_df.columns = ['id','place_name','category','rating','price']
df = rating.copy()

# user sampling
user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

# unvisited location data
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user.Place_Id.values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

"""**Showing the Recomendation for Users**"""

# top 7 recommendations
ratings = model.predict(user_place_array).flatten()
top_ratings_indices = ratings.argsort()[-7:][::-1]
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices
]

print('Recommendation list for: {}'.format('User ' + str(user_id)))
print('===' * 15,'\n')
print('----' * 15)
print('Places with highest rating from users')
print('----' * 15)

top_place_user = (
    place_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)

place_df_rows = place_df[place_df['id'].isin(top_place_user)]
for row in place_df_rows.itertuples():
    print(row.place_name, ':', row.category)

print('')
print('----' * 15)
print('Top 7 place recommendations')
print('----' * 15)

recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]
for row, i in zip(recommended_place.itertuples(), range(1,8)):
    print(i,'.', row.place_name, '\n    ', row.category, ',', 'Entrance Fee', row.price, ',', 'Rating', row.rating,'\n')

print('==='*15)

"""Hasil rekomendasi menampilkan top 7 destinasi sesuai dengan preferensi pengguna."""